---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Garbage Can Regression Challenge

**Choose R or Python and delete the other code chunk.**

## R Code

```{r}
#| echo: true
library(tidyverse)
library(broom)

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
observDF <- tribble(
  ~Stress, ~StressSurvey, ~Time, ~Anxiety,
  0,0,0,0,
  0,0,1,0.1,
  0,0,1,0.1,
  1,3,1,1.1,
  1,3,1,1.1,
  1,3,1,1.1,
  2,6,2,2.2,
  2,6,2,2.2,
  2,6,2,2.2,
  8,9,2,8.2,
  8,9,2,8.2,
  8,9,2.1,8.21,
  12,12,2.2,12.22,
  12,12,2.2,12.22,
  12,12,2.2,12.22
)

observDF

# Follow the challenge instructions from your course to complete your analysis.
# Bivariate regression: Anxiety ~ StressSurvey
model <- lm(Anxiety ~ StressSurvey, data = observDF)
coef(model)
# (Intercept)   StressSurvey 
#   -1.524000      1.047000


# Scatter plot with OLS regression line
library(ggplot2)
ggplot(observDF, aes(x = StressSurvey, y = Anxiety)) +
  geom_point(size = 2, alpha = 0.9) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue", linewidth = 1) +
  labs(
    title = "Anxiety vs. StressSurvey with OLS fit",
    x = "StressSurvey",
    y = "Anxiety"
  )
# As the level of anxiety increases, the level of stress survey also increases. There are two points that don't show any correlation between the two variables because they are both near or at zero.


# Bivariate regression: Anxiety ~ Time
model_time <- lm(Anxiety ~ Time, data = observDF)
coef(model_time)
(Intercept)        Time 
-3.68013      5.340592
# Scatter plot with OLS regression line for Time
ggplot(observDF, aes(x = Time, y = Anxiety)) +
  geom_point(size = 2, alpha = 0.9) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen", linewidth = 1) +
  labs(
    title = "Anxiety vs. Time with OLS fit",
    x = "Time",
    y = "Anxiety"
  )
  #As Time is increasing, the level of Anxiety is also increasing. There is an extreme outlier on Anxiety. This is likely due to the fact that the data is not normally distributed. I also believe that there could be a better line of best fit.


# Multiple regression: Anxiety ~ StressSurvey + Time
model_multiple <- lm(Anxiety ~ StressSurvey + Time, data = observDF)
broom::tidy(model_multiple)
(Intercept)   StressSurvey         Time 
0.5896064       1.43               -2.78
#They compare to the true relationships. The StressSurvey and Time are not significant. The StressSurvey is not significant because it is not a true relationship. The Time is not significant because it is not a true relationship.

# Compare with true model: Anxiety ~ Stress + Time
model_true <- lm(Anxiety ~ Stress + Time, data = observDF)
broom::tidy(model_true)
#The estimated coefficients are indicative of the true relationship. It compares to the true relationship because it is a perfect fit.

#True model (Anxiety ~ Stress + Time): likely ~1.00 because the data were generated as Anxiety = Stress + 0.1 × Time. It's a perfect fit. Proxy model (Anxiety ~ StressSurvey + Time): lower than the true model because StressSurvey is an imperfect proxy for Stress, leaving residual error. It's not a perfect fit. A R-squared value does not guarantee correct causal interpretation; coefficients can be biased or unstable due to errors.

#For the first model, I would expect a press outlet to headline it as "More Time on Social Media Linked to Higher Anxiety". For the second model, "Stress attributed to a higher level of anxiety". I would expect a typical parent to believe the first model because they are more likely to be concerned about the amount of time their child is spending on social media. Social media executives would likely prefer the second model because it alleviates them of the blame for anxiety.


# Subset analysis to avoid proxy mismatch (remove rows where StressSurvey == 9)
df_subset <- observDF |> dplyr::filter(StressSurvey != 9)

# Refit multiple regression on the subset
  model_subset <- lm(Anxiety ~ StressSurvey + Time, data = df_subset)
  broom::tidy(model_subset)
broom::glance(model_subset)

# Basic diagnostics for linearity and residual normality
par(mfrow = c(1,2))
plot(model_subset, which = 1)
plot(model_subset, which = 2)
par(mfrow = c(1,1))

# Visual check: Anxiety vs Time colored by StressSurvey levels
ggplot(df_subset, aes(x = Time, y = Anxiety, color = factor(StressSurvey))) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Anxiety ~ Time by StressSurvey (subset without 9)", color = "StressSurvey")

# Inspect estimated Time effect relative to true 0.1
coef(model_subset)["Time"]
#The estimated Time effect is -2.78, which is significantly different from the true relationship of 0.1. This is likely due to the fact that the data is not normally distributed.
#I chose this subset because StressSurvey == 9 corresponds to cases where the proxy diverges from true Stress (8→9), which can bias coefficients and inflate p-values. Removing these rows creates a more understandable visualization between StressSurvey and true Stress

```
## Your Analysis

